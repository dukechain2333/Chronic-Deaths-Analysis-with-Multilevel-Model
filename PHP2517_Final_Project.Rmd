---
title: "PHP2517 Final Project"
author: "Peirong Hao, William Qian"
output:
  pdf_document: default
header-includes: \usepackage{fvextra} \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
---

```{r setup, include=FALSE}
# https://yihui.org/knitr/options/
knitr::opts_chunk$set(message=FALSE, 
                      warning=FALSE, 
                      error=FALSE, 
                      echo = FALSE, 
                      fig.pos = "H" ,
                      fig.align = 'center',
                      tidy=TRUE, tidy.opts=list(width.cutoff=80))

library(tidyverse)
library(knitr)
set.seed(123)
library(tidyr)       ## Used to tidy data
library(dplyr)       ## Used to manipulate data
library(gtsummary)
library('caret')
library(corrplot)
library(lmerTest)
library(ggplot2)
library(usmap)
```

# Introduction

According to [1], chronic diseases are severe conditions that can get worse over time. Their controllable but not curable feature pose significant challenges to public health systems [1]. Common conditions, including “cancer, heart disease, stroke, diabetes, and arthritis,” not only lead to prolonged illness but also contribute substantially to the economic burden faced by societies [1]. Traditional epidemiological studies utilize simple statistical models that might not account for the complexity of state-level and region-level determinants of health. As a result, there is a pressing need for more sophisticated analytical approaches to provide a deeper understanding of the factors influencing chronic disease mortality.

Multilevel modeling (MLM), or hierarchical linear modeling, offers a robust statistical framework for analyzing data structures at multiple levels. This approach is particularly suitable for public health research, where data often involve nested structures, such as patients within hospitals. MLM allows researchers to explore the impact of different level predictors and how these effects vary across groups. This study aims to employ multilevel models to analyze chronic disease mortality data, focusing on identifying critical state-level and region-level predictors. By integrating multiple levels of data, this research seeks to uncover potential targets for intervention that could mitigate the risk factors associated with chronic diseases. 

# Data Source

Our data come from the Dartmouth Atlas Project [2]. This site offers access to decades of Medicare data and supplemental materials. Our data are from 2019 and initially have 68 covariates. In terms of data preprocessing, we first look through all variables and try to identify variables with similar meanings. To the best of our knowledge, we only keep variables that have distinct meanings and remove other variables with duplicated information. For example, when we retain variables of `Ratio to the U.S. Average`, we remove the corresponding variables that record the actual numbers. After we choose the `Total` variables, we drop the other variables related to sub-categories. In addition, we remove the `System` variable due to a large proportion (20%) of missing values in in its column. There is an error with the variable `Hospice Days per Decedent during the Last Six Months of Life`, it is more likely to refer to reimbursements than days (data summary has a mean = 1091, min = 1, max = 2180, similar to summaries of other reimbursement variables). So we drop this variable as well. The last step of data cleaning is removing rows with NA values. The final dataset involves 2174 observations and 32 variables: 2 categorical variables are State and Region, and the rest are all numeric. Our outcome in this project is “Number of deaths among chronically ill patients assigned to hospital.” We are concerned about the predictability of both longer-term (two years) and the shorter-term (six months) variables on our outcome of interest. 

# Pre-Proccessing of Data

First of all, to better analyze the pattern of the data, we would like to add a column of `Region` based on the `State` column. We divide the states into four regions: Northeast, Midwest, South, and West. We then check the missing values in the dataset.


```{r}
library(readxl)
df.chronic <-read_excel('hosp_eolchronic_dead6699ffs_2019.xlsx')

#first convert columns to factor or numeric columns

#relevel: first level is state, second level is region
#https://www.bu.edu/brand/guidelines/editorial-style/us-state-abbreviations/
#https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf
#Note: 1 state is US(unsure), so remove that obervation

# Since the column `Hospice Days per Decedent during the Last Six Months of Life` is mislabed, we will remove it from the data

df.chronic <- df.chronic %>% select(-`Hospice Days per Decedent during the Last Six Months of Life`)

df.chronic <- df.chronic %>% mutate_if(is.character,as.factor) %>% 
  mutate(across(.cols = c(
  `SNF/Long-Term Care Sector Reimbursements per Decedent during the Last Two Years of Life`,
  `Hospice Sector Reimbursements per Decedent during the Last Two Years of Life`,
  `Total ICU Bed Inputs per 1,000 Decedents during the Last Two Years of Life`,
  `High-Intensity ICU Bed Inputs per 1,000 Decedents during the Last Two Years of Life`,
  `Intermediate-Intensity ICU Bed Inputs per 1,000 Decedents during the Last Two Years of Life`,
  `Medical & Surgical Unit Bed Inputs per 1,000 Decedents during the Last Two Years of Life`,
  `SNF Bed Inputs per 1,000 Dededents during the Last Two Years of Life`,,
  `RNs Required Under Proposed Federal Standards per 1,000 Decedents during the Last Two Years of Life`,
  `High-Intensity ICU Days per Decedent during the Last Six Months of Life`,
  `Intermediate-Intensity ICU Days per Decedent during the Last Six Months of Life`,
  `Medical & Surgical Unit Days per Decedent during the Last Six Months of Life`,
  `Percent of Decedents Enrolled In Hospice during the Last Six Months of Life`),~as.numeric(.)))%>%
  mutate(Region = case_when(State %in% c("CT","ME","MA","NH","RI","VT","NJ","NY","PA") ~ "Northeast",
                            State %in% c("IN","IL","MI","OH","WI","IA","KS","MN","MO","NE","ND","SD") ~ "Midwest",
                            State %in% c("DE","DC","FL","GA","MD","NC","SC","VA","WV","AL","KY","MS","TN","AR","LA","OK","TX") ~ "South",
                            State %in% c("AZ","CO","ID","NM","MT","UT","NV","WY","AK","CA","HI","OR","WA") ~ "West"),
         Region = factor(Region))%>% 
  filter(State!="US")
  # filter(!is.na(Region))

# summary(df.chronic)
# summary(df.chronic$State)
# summary(df.chronic$Region)
```

Then, we tried to find the columns with missing values and the ratio of missing values in these columns. We found that the `System` column has 20% missing values, and the `Ambulance spending per Decedent during the last two years of life` column has 0.4% missing values. We decided to remove the `System` column and remove the rows with missing values in the `Ambulance spending per Decedent during the last two years of life` column. Furthermore, from the description of the dataset, we know that there are some columns use negative values to represent missing values. We will replace these negative values with NA. Finally, we will remove the rows with NA values and check the proportion of zeros in each column.

```{r}
# check which cols have na values
na_cols <- colnames(df.chronic)[colSums(is.na(df.chronic)) > 0]

# check the ratio of NAs in these columns
na_ratio <- colSums(is.na(df.chronic[na_cols])) / nrow(df.chronic)
#na_ratio
```

```{r}
# since `System` has 20% missing values, we are going to remove this column
df.chronic <- df.chronic %>% select(-System)

# `Ambulance spending per Decedent during the last two years of life` has 0.4% missing values, we are going to remove these rows
df.chronic <- df.chronic %>% drop_na(`Ambulance spending per Decedent during the last two years of life`)

df.chronic[df.chronic<0] <- NA
# add check for proportion of zeros in each column
df.chronic <- df.chronic %>% drop_na()
```

To be noticed that, we did find a lot of variables in the dataset seems to be overlapping with each other. For example, `Total ICU Bed Inputs per 1,000 Decedents during the Last Two Years of Life` and `High-Intensity ICU Bed Inputs per 1,000 Decedents during the Last Two Years of Life` are tow sets that share the same subset which is `High-Intensity ICU Bed Inputs per 1,000 Decedents during the Last Two Years of Life`, we will remove the `High-Intensity ICU Bed Inputs per 1,000 Decedents during the Last Two Years of Life` column. 

After a detailed examination of the dataset, we will remove these variables: `HRR`, `HRR Name`, `Provider ID`, `City`, `Inpatient Sector Reimbursements per Decedent during the Last Two Years of Life`, `Outpatient Sector Reimbursements per Decedent during the Last Two Years of Life`, `SNF/Long-Term Care Sector Reimbursements per Decedent during the Last Two Years of Life`, `Home Health Sector Reimbursements per Decedent during the Last Two Years of Life`, `Hospice Sector Reimbursements per Decedent during the Last Two Years of Life`, `Reimbursements for Durable Medical Equipment per Decedent during the Last Two Years of Life`, `Ambulance spending per Decedent during the last two years of life`, `Part B Spending for Evaluation & Management per Decedent during the Last Two Years of Life`,`Part B Spending for Procedures per Decedent during the Last Two Years of Life`, `Part B Spending for Imaging per Decedent during the Last Two Years of Life`, `Part B Spending for Tests per Decedent during the Last Two Years of Life`, `Other Part B spending per Decedent during the last two years of life`, `Inpatient Days per Decedent during the Last Two Years of Life`, `Reimbursements per patient day (calculated)`, `Reimbursements per Day: Ratio to US Average (calculated)`, `Hospital reimbursements per Decedent during the last two years of life`, `Payments per physician visit (calculated)`, `Payments for physician visits per Decedent during the last two years of life`, `Physician Visits per Decedent during the Last Two Years of Life`, `Payments per visit: Ratio to US Average (calculated)`, `FTE Physician Labor Inputs per 1,000 Decedents during the Last Two Years of Life`, `FTE Medical Specialist Labor Inputs per 1,000 Decedents during the Last Two Years of Life`, `FTE Primary Care Physician Labor Inputs per 1,000 Decedents during the Last Two Years of Life`, `Average Co-Payments for Physician Services per Decedent during the Last Two Years of Life`, `Average Co-Payments for Durable Medical Equipment per Decedent during the Last Two Years of Life`, `Percent of Deaths Occurring In Hospital`, `Percent of Deaths Associated With ICU Admission`, `Physician Visits per Decedent during the Last Six Months of Life`, `Medical Specialist Visits per Decedent during the Last Six Months of Life`, `Primary Care Visits per Decedent during the Last Six Months of Life` and `Percent of Decedents Seeing 10 or More Different Physicians during the Last Six Months of Life`.

```{r}
#"Hospital Name"
cols_to_drop <- c("HRR", "HRR Name", "Provider ID", "City", "Inpatient Sector Reimbursements per Decedent during the Last Two Years of Life", "Outpatient Sector Reimbursements per Decedent during the Last Two Years of Life", "SNF/Long-Term Care Sector Reimbursements per Decedent during the Last Two Years of Life", "Home Health Sector Reimbursements per Decedent during the Last Two Years of Life", "Hospice Sector Reimbursements per Decedent during the Last Two Years of Life", "Reimbursements for Durable Medical Equipment per Decedent during the Last Two Years of Life", "Ambulance spending per Decedent during the last two years of life", "Part B Spending for Evaluation & Management per Decedent during the Last Two Years of Life","Part B Spending for Procedures per Decedent during the Last Two Years of Life", "Part B Spending for Imaging per Decedent during the Last Two Years of Life", "Part B Spending for Tests per Decedent during the Last Two Years of Life", "Other Part B spending per Decedent during the last two years of life", "Inpatient Days per Decedent during the Last Two Years of Life", "Reimbursements per patient day (calculated)", "Reimbursements per Day: Ratio to US Average (calculated)", "Hospital reimbursements per Decedent during the last two years of life", "Payments per physician visit (calculated)", "Payments for physician visits per Decedent during the last two years of life", "Physician Visits per Decedent during the Last Two Years of Life", "Payments per visit: Ratio to US Average (calculated)", "FTE Physician Labor Inputs per 1,000 Decedents during the Last Two Years of Life", "FTE Medical Specialist Labor Inputs per 1,000 Decedents during the Last Two Years of Life", "FTE Primary Care Physician Labor Inputs per 1,000 Decedents during the Last Two Years of Life", "Average Co-Payments for Physician Services per Decedent during the Last Two Years of Life", "Average Co-Payments for Durable Medical Equipment per Decedent during the Last Two Years of Life", "Percent of Deaths Occurring In Hospital", "Percent of Deaths Associated With ICU Admission", "Physician Visits per Decedent during the Last Six Months of Life", "Medical Specialist Visits per Decedent during the Last Six Months of Life", "Primary Care Visits per Decedent during the Last Six Months of Life", "Percent of Decedents Seeing 10 or More Different Physicians during the Last Six Months of Life")

df.chronic <- df.chronic %>% select(-cols_to_drop)
```

Now, let's examine the corelation between the numeric variables in the dataset. A correlation plot can help us to identify the highly correlated variables.

```{r}
plot_correlation <- function(df){
  dat <- as.matrix(df)
  dimnames(dat) <- list(rep("", ncol(dat)), rep("", ncol(dat)))
  dat[upper.tri(dat)] <- 0
  
  corrplot(dat, type = "lower" , title="Correlation Plot",cex.main=0.7)
    # corrplot(dat, type = "lower" , title="Correlation Plot", mar=c(0,0,0,0), cex.main=0.7, number.cex=0.7, tl.cex = 0.7, cl.cex = 0.7)
}
```

```{r,out.height="70%"}
df.numeric <- df.chronic %>%  select_if(is.numeric)
df.cat <- df.chronic  %>% select_if(is.factor)

cor.df.numeric <- cor(df.numeric, use = "complete.obs")
plot_correlation(cor.df.numeric)
```

Although we have manually filtered out a lot of overlapping variables in the previous step, we can see that there are many highly correlated variables in the dataset. This is probably due to those variables has causal effects with each other, and if we include all of them in the model, it will cause problems. We will remove the highly correlated variables using a threshold of 0.3.

```{r}
# remove highly correlated variables
hc <- findCorrelation(cor.df.numeric, cutoff=0.3)
hc <- sort(hc)
df.numeric <- df.numeric[,-c(hc)]

cor.df.numeric <- cor(df.numeric, use = "complete.obs")
plot_correlation(cor.df.numeric)

# combine it with categorical variables
df.cat <- df.chronic  %>% select_if(is.factor)

df.chronic <- cbind(df.cat, df.numeric)

col.df<-colnames(df.chronic)
col.df
```

Most of the variables that are highly correlated with each other have been removed. There are 13 variables left in the dataset.

# Exploratory Data Analysis

We will start by checking the map of the United States to see the distribution of the data. We will use the `ggplot2` package to plot the map of the United States and color the states based on the number of deaths among chronically ill patients assigned to hospital.

```{r}
state.summ <- df.chronic %>%
  group_by(State) %>%
  summarise(total = sum(`Number of deaths among chronically ill patients assigned to hospital`, na.rm = T)) %>%
  rename(state = State)

plot_usmap(data = state.summ, values = "total", lines = "white") +
  scale_fill_continuous(name = "total", low = "blue", high = "red", label = scales::comma) +
  theme(legend.position = "right") +
  labs(title = "Total Chronic Deaths by State")


```
To make the data more clear, we also provide a table of the summary of the number of deaths by region and state.

```{r}
library(kableExtra)

overall_summary <- df.chronic %>%
  group_by(Region, State) %>%
  summarise(
  n = (length(`Number of deaths among chronically ill patients assigned to hospital`)-sum(is.na(`Number of deaths among chronically ill patients assigned to hospital`))),
  total = sum(`Number of deaths among chronically ill patients assigned to hospital`, na.rm = T),
  mean = round(mean(`Number of deaths among chronically ill patients assigned to hospital`, na.rm = T), 3),
  sd = round(sd(`Number of deaths among chronically ill patients assigned to hospital`, na.rm = T), 3),
  median = round(median(`Number of deaths among chronically ill patients assigned to hospital`, na.rm = T), 3),
  min = round(min(`Number of deaths among chronically ill patients assigned to hospital`, na.rm = T), 3),
  max = round(max(`Number of deaths among chronically ill patients assigned to hospital`, na.rm = T), 3))%>%
  ungroup()

#output table for overall averages
overall_summary %>%
  mutate_all(linebreak) %>%
  kbl(caption = "Summary of Number of deaths",
  col.names=linebreak(c("Region", "State", "N", "Total", "Mean", "SD", "Median", "Min", "Max")),
  booktabs=T, escape=F, align = "c") %>%
kable_styling(full_width = FALSE, latex_options = c('hold_position'))

#overall_summary
```

We might also want to see the variance of the number of deaths by states and regions.

```{r}
df.chronic %>%
  group_by(State) %>%
  summarise(var_dead = var(`Number of deaths among chronically ill patients assigned to hospital`)) %>%
  ggplot(aes(x = State, y = var_dead)) +
  geom_bar(stat = "identity") +
  labs(title = "Variance of Number of deaths by States",
       x = "States",
       y = "Variance of Number of deaths") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r}
df.chronic %>%
  group_by(Region) %>%
  summarise(var_dead = var(`Number of deaths among chronically ill patients assigned to hospital`)) %>%
  ggplot(aes(x = Region, y = var_dead)) +
  geom_bar(stat = "identity") +
  labs(title = "Variance of Number of deaths by Region",
       x = "States",
       y = "Variance of Number of Region") +
  theme_minimal()
```
We do find that the total number of deaths varies significantly across states and regions. This suggests that there might be some state-level and region-level predictors that can explain the variance in the number of deaths among chronically ill patients assigned to hospital. Now, we would like to see if the predictors in the dataset are significantly different across regions and states.

The following table shows the summary of the variables by region. We can see that the variables are significantly different across regions.

```{r}
df.summary.region<-df.chronic %>% select(-c(State,`Hospital Name`)) %>%
  tbl_summary(missing="no",
              by = Region, 
              type = list(where(is.numeric) ~ "continuous"),
              statistic = list(all_continuous() ~ "{mean} ({sd})")) %>% add_p()%>%
  modify_caption("Summary of Variables by Region")
df.summary.region
```

And this table shows the summary of the variables by state. We can see that the variables are significantly different across states.

```{r}
df.summary.state<-df.chronic %>% select(-c(Region,`Hospital Name`)) %>%
  tbl_summary(missing="no",
              by = State, 
              type = list(where(is.numeric) ~ "continuous"),
              statistic = list(all_continuous() ~ "{mean} ({sd})")) %>% add_p()%>%
  modify_caption("Summary of Variables by State")
df.summary.state
```

```{r fig.height=10, fig.width=20}
library(DataExplorer)

plot_histogram(df.chronic)
```

```{r fig.height=10, fig.width=20}
df.chronic$`Home Health Agency Visits per Decedent during the Last Six Months of Life` <- log(df.chronic$`Home Health Agency Visits per Decedent during the Last Six Months of Life` + 1)
df.chronic$`Other spending per Decedent during the last two years of life` <- log(df.chronic$`Other spending per Decedent during the last two years of life` + 1)
df.chronic$`Standardized FTE physician labor: Ratio MS/PC (calculated)` <- log(df.chronic$`Standardized FTE physician labor: Ratio MS/PC (calculated)` + 1)

plot_histogram(df.chronic)
```

Based on the exploratory data analysis, we find that the number of deaths among chronically ill patients assigned to hospital varies significantly across states and regions. This suggests that a multilevel model might be more appropriate for analyzing the data. In the next section, we will use generalized linear models (GLM) to do the variable selection and then fit a multilevel model to the data. Our multilevel model will include two levels: state-level and hospital-level. We will use the `lmer` function to fit the multilevel model and use the `anova` test to compare the models with and without random effects to determine the best model.

With regards to the multilevel structure of the data, level 1 refers to the State, and level 2 is the Region (we manually convert states to four regions: Midwest, Southeast, South, and West). After constructing models, we compare their AIC values to determine the better model. 

$Y_{ij}\sim N(\beta_j, \sigma^2), \beta_j\sim N(\mu,\tau^2)$ 

```{r}
library(lme4)
m1<-glmer(`Number of deaths among chronically ill patients assigned to hospital` ~1+(1|State),data=df.chronic, family=poisson)
summ1<-summary(m1)
```

* Summary table
```{r}
VarCorr(m1)
```

```{r}
summ1$coefficients
```

```{r}
m2<-glmer(`Number of deaths among chronically ill patients assigned to hospital` ~1+(1|Region),data=df.chronic, family=poisson)
summ2<-summary(m2)
```

* Summary table
```{r}
VarCorr(m2)
```

```{r}
summ2$coefficients
```

```{r}
AIC(m1,m2)
```

Because m1 has a slightly lower AIC value, m1 is the better model. Intercept variance = $(35.544)^2 = 1263.376$ represents how much variance in outcome (number of deaths) that is explained between states. Residual variance = $(219.670)^2 = 48254.91$ represents the within state unexplained variance. $\beta_{0}+b_{0j}=305.5872+b_{0j}$ represents the estimated number of deaths (individual intercept) for the jth state.

# Variable Selection via GLM

```{r}
glm.model.full <- glm(`Number of deaths among chronically ill patients assigned to hospital` ~ 1+
                      `Other spending per Decedent during the last two years of life` +
                      `Total ICU Bed Inputs per 1,000 Decedents during the Last Two Years of Life` + 
                      `High-Intensity ICU Bed Inputs per 1,000 Decedents during the Last Two Years of Life` + 
                      `Intermediate-Intensity ICU Bed Inputs per 1,000 Decedents during the Last Two Years of Life` +
                      `SNF Bed Inputs per 1,000 Dededents during the Last Two Years of Life` + 
                      `Standardized FTE physician labor: Ratio MS/PC (calculated)` +
                      `Medical & Surgical Unit Days per Decedent during the Last Six Months of Life` +
                      `Home Health Agency Visits per Decedent during the Last Six Months of Life` +
                      `Percent of Decedents Enrolled In Hospice during the Last Six Months of Life`, data=df.chronic, family=poisson)

summary(glm.model.full)
```

```{r}
glm.model.1 <- glm(`Number of deaths among chronically ill patients assigned to hospital` ~ 1+
                      `Other spending per Decedent during the last two years of life` +
                      `Total ICU Bed Inputs per 1,000 Decedents during the Last Two Years of Life` + 
                      `High-Intensity ICU Bed Inputs per 1,000 Decedents during the Last Two Years of Life` + 
                      `SNF Bed Inputs per 1,000 Dededents during the Last Two Years of Life` + 
                      `Standardized FTE physician labor: Ratio MS/PC (calculated)` +
                      `Medical & Surgical Unit Days per Decedent during the Last Six Months of Life` +
                      `Home Health Agency Visits per Decedent during the Last Six Months of Life` +
                      `Percent of Decedents Enrolled In Hospice during the Last Six Months of Life`, data=df.chronic, family=poisson)

summary(glm.model.1)
```

# Adding Random Effect to the Model

In the previous section, we have used GLM to do the variable selection. However, in the exploratory data analysis, we have found that there seems to be a difference between region and states, suggesting that a multilevel model might be more appropriate. Adding a random effect to the model can help us to account for the variance between groups, thus providing a more accurate estimate of the predictions.

In this section, we will use the `lmer` function to fit a multilevel model to the data. However, different with the previous part, we will use a forward selection. We will start with the simplest model, which only includes the variables we found in the previous section. We will then add one variable at a time and use `anova` test to check the AIC value and p-values to determine if we will keep the variable in the model. For instance, if the p-value suggests that the two model are not significantly different, we will remove the variable from the model, in other words, we will keep the simple model with fewer variables when the two models are not significantly different. On the other hand, when the p-value suggests that the two models are significantly different, we will keep the more complex model with more variables (usually has a lower AIC value).

We will start by adding the random effect on `State` to the model. The model is `lmer.model.1`.

```{r}
glmer.model<-glmer(`Number of deaths among chronically ill patients assigned to hospital` ~1+
                      `Other spending per Decedent during the last two years of life` +
                      `Total ICU Bed Inputs per 1,000 Decedents during the Last Two Years of Life` + 
                      `High-Intensity ICU Bed Inputs per 1,000 Decedents during the Last Two Years of Life` + 
                      `SNF Bed Inputs per 1,000 Dededents during the Last Two Years of Life` + 
                      `Standardized FTE physician labor: Ratio MS/PC (calculated)` +
                      `Medical & Surgical Unit Days per Decedent during the Last Six Months of Life` +
                      `Home Health Agency Visits per Decedent during the Last Six Months of Life` +
                      `Percent of Decedents Enrolled In Hospice during the Last Six Months of Life` + 
                      (1|State), data=df.chronic, family=poisson)

glmer.model.summ <- summary(glmer.model)
```

```{r}
AIC(glm.model.1, glmer.model)
```

# Model Comparison

```{r}
glmer.model.best <- glmer.model
glm.model.best <- glm.model.1
```

* Fixed effects:

```{r}
glmer.model.best.fixef<-fixef(glmer.model.best)
glmer.model.best.fixef
```

```{r}
glmer.model.best.ranef.state <- ranef(glmer.model.best)[[1]]
```

```{r}
glmer.model.best.predict <- predict(glmer.model.best)
glm.model.best.predict <- predict(glm.model.best)

# mse for lmer model
glmer.model.best.mse <- mean((df.chronic$`Number of deaths among chronically ill patients assigned to hospital` - glmer.model.best.predict)^2)
print(lmer.model.best.mse)

# mse for glm model
glm.model.best.mse <- mean((df.chronic$`Number of deaths among chronically ill patients assigned to hospital` - glm.model.best.predict)^2)
print(glm.model.best.mse)
```

```{r}
df.chronic.filter <- df.chronic %>% 
  filter(`Hospital Name` %in% row.names(lmer.model.best.ranef.hospital))

lmer.model.best.ranef.hospital.altered <- lmer.model.best.ranef.hospital %>% 
  rename_with(~paste0("RE-", gsub("`", "", .)), everything()) %>%
  rownames_to_column(var = "Hospital Name")

lmer.model.best.ranef.state.altered <- lmer.model.best.ranef.state %>% 
  rename("RE-State" = "(Intercept)") %>%
  rownames_to_column(var = "State")

result_df <- inner_join(df.chronic.filter, lmer.model.best.ranef.hospital.altered, by = "Hospital Name")
result_df <- inner_join(result_df, lmer.model.best.ranef.state.altered, by = "State")
result_df$predicted <- predict(lmer.model.best, newdata = df.chronic.filter)

names(result_df)
head(result_df)
```

# References

[1] https://www.cancer.gov/publications/dictionaries/cancer-terms/def/chronic-disease

[2] https://data.dartmouthatlas.org/eol-chronic/

# Code Appendix

```{r ref.label=knitr::all_labels(), echo=TRUE, eval=FALSE}
```
